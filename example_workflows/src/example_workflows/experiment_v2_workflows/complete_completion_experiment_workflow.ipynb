{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Two Completion Workflows - Complete Verification\n",
        "\n",
        "This notebook demonstrates and verifies 2 consecutive completion workflows with head-to-tail chaining.\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   TWO COMPLETION WORKFLOWS - CHAINING       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "                START\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  1. Create Experiment       ‚îÇ\n",
        "    ‚îÇ     (2 completion workflows)‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  2. Workflow 1: Summarize   ‚îÇ\n",
        "    ‚îÇ     (Input ‚Üí Brief Summary) ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  3. Workflow 2: Expand      ‚îÇ\n",
        "    ‚îÇ     (Summary ‚Üí Detailed)    ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  4. Evaluators Run          ‚îÇ\n",
        "    ‚îÇ     (on final output)       ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  5. View Results            ‚îÇ\n",
        "    ‚îÇ     (with chaining verified)‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "                 END\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your API key and base URL here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "loaded = load_dotenv(override=True)\n",
        "\n",
        "# API Configuration\n",
        "BASE_URL = os.getenv(\"KEYWORDSAI_BASE_URL\")\n",
        "API_KEY = os.getenv(\"KEYWORDSAI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError(\n",
        "        \"‚ùå KEYWORDSAI_API_KEY environment variable not set!\\n\"\n",
        "        \"Make sure you have a .env file with: KEYWORDSAI_API_KEY=your-api-key-here\\n\"\n",
        "        \"Or set it with: export KEYWORDSAI_API_KEY='your-api-key-here'\"\n",
        "    )\n",
        "\n",
        "print(f\"Loaded .env from {os.getcwd()}/.env: {loaded}\")\n",
        "print(f\"‚úÖ API Key loaded: {API_KEY[:8]}{'*' * 20}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and All Functions\n",
        "\n",
        "All necessary imports and function definitions in one place.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import requests\n",
        "from typing import Dict, Any, List, Optional\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def print_step(step_number: int, title: str):\n",
        "    \"\"\"Print a formatted step header.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"STEP {step_number}: {title}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "def print_success(message: str):\n",
        "    \"\"\"Print a success message.\"\"\"\n",
        "    print(f\"‚úÖ {message}\")\n",
        "\n",
        "def print_warning(message: str):\n",
        "    \"\"\"Print a warning message.\"\"\"\n",
        "    print(f\"‚ö†Ô∏è  {message}\")\n",
        "\n",
        "def print_error(message: str):\n",
        "    \"\"\"Print an error message.\"\"\"\n",
        "    print(f\"‚ùå {message}\")\n",
        "\n",
        "def print_info(message: str):\n",
        "    \"\"\"Print an info message.\"\"\"\n",
        "    print(f\"‚ÑπÔ∏è  {message}\")\n",
        "\n",
        "def wait_for_processing(seconds: int = 15):\n",
        "    \"\"\"Wait for async processing to complete.\"\"\"\n",
        "    print(f\"\\nWaiting {seconds} seconds for processing...\")\n",
        "    time.sleep(seconds)\n",
        "    print(\"‚úì Wait complete\")\n",
        "\n",
        "# ============================================================================\n",
        "# API FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_log(\n",
        "    model: str,\n",
        "    input_messages: List[Dict[str, str]],\n",
        "    output_message: Dict[str, str],\n",
        "    custom_identifier: Optional[str] = None,\n",
        "    span_name: Optional[str] = None,\n",
        "    **kwargs\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a new log entry in Keywords AI.\"\"\"\n",
        "    url = f\"{BASE_URL}/request-logs/create\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"input\": input_messages,\n",
        "        \"output\": output_message\n",
        "    }\n",
        "    \n",
        "    if custom_identifier:\n",
        "        payload[\"custom_identifier\"] = custom_identifier\n",
        "    if span_name:\n",
        "        payload[\"span_name\"] = span_name\n",
        "    \n",
        "    payload.update(kwargs)\n",
        "    \n",
        "    print(\"Creating log entry...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Model: {model}\")\n",
        "    print(f\"  Input messages: {len(input_messages)}\")\n",
        "    if custom_identifier:\n",
        "        print(f\"  Custom identifier: {custom_identifier}\")\n",
        "    if span_name:\n",
        "        print(f\"  Span name: {span_name}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Log created successfully\")\n",
        "    if 'unique_id' in data:\n",
        "        print(f\"  Log ID (unique_id): {data.get('unique_id')}\")\n",
        "    if 'id' in data:\n",
        "        print(f\"  Log ID: {data.get('id')}\")\n",
        "    if 'trace_id' in data:\n",
        "        print(f\"  Trace ID: {data.get('trace_id')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_dataset(\n",
        "    name: str, \n",
        "    description: str = \"\", \n",
        "    dataset_type: str = \"sampling\",\n",
        "    sampling: int = 50,\n",
        "    start_time: Optional[str] = None,\n",
        "    end_time: Optional[str] = None,\n",
        "    initial_log_filters: Optional[Dict[str, Any]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a new dataset from logs with sampling and filtering.\"\"\"\n",
        "    url = f\"{BASE_URL}/datasets\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"type\": dataset_type\n",
        "    }\n",
        "    \n",
        "    if sampling and not initial_log_filters:\n",
        "        payload[\"sampling\"] = sampling\n",
        "    \n",
        "    if start_time:\n",
        "        payload[\"start_time\"] = start_time\n",
        "    if end_time:\n",
        "        payload[\"end_time\"] = end_time\n",
        "        \n",
        "    if initial_log_filters:\n",
        "        payload[\"initial_log_filters\"] = initial_log_filters\n",
        "    \n",
        "    print(\"Creating dataset...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Type: {dataset_type}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Dataset created successfully\")\n",
        "    print(f\"  Dataset ID: {data.get('id')}\")\n",
        "    print(f\"  Name: {data.get('name')}\")\n",
        "    print(f\"  Status: {data.get('status', 'N/A')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def list_dataset_logs(dataset_id: str, page: int = 1, page_size: int = 100) -> Dict[str, Any]:\n",
        "    \"\"\"List logs from a specific dataset.\"\"\"\n",
        "    url = f\"{BASE_URL}/datasets/{dataset_id}/logs/list\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    params = {\n",
        "        \"page\": page,\n",
        "        \"page_size\": page_size\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nListing logs for dataset {dataset_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Method: GET\")\n",
        "    print(f\"  Params: {params}\")\n",
        "    \n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    results = data.get('results', [])\n",
        "    total_count = data.get('count', 0)\n",
        "    \n",
        "    print(f\"‚úì Retrieved {len(results)} logs (page {page})\")\n",
        "    print(f\"  Total logs in dataset: {total_count}\")\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\n  üìã First log structure:\")\n",
        "        first_log = results[0]\n",
        "        print(f\"    Keys: {list(first_log.keys())}\")\n",
        "        if 'id' in first_log:\n",
        "            print(f\"    Log ID: {first_log.get('id')}\")\n",
        "        if 'input' in first_log:\n",
        "            input_preview = str(first_log.get('input'))[:100]\n",
        "            print(f\"    Input preview: {input_preview}...\")\n",
        "        if 'output' in first_log:\n",
        "            output_preview = str(first_log.get('output'))[:100]\n",
        "            print(f\"    Output preview: {output_preview}...\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_evaluator(\n",
        "    name: str,\n",
        "    evaluator_slug: str,\n",
        "    evaluator_type: str,\n",
        "    score_value_type: str,\n",
        "    description: str = \"\",\n",
        "    configurations: Optional[Dict[str, Any]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a custom evaluator in Keywords AI.\"\"\"\n",
        "    url = f\"{BASE_URL}/evaluators\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"evaluator_slug\": evaluator_slug,\n",
        "        \"type\": evaluator_type,\n",
        "        \"score_value_type\": score_value_type,\n",
        "        \"description\": description\n",
        "    }\n",
        "    \n",
        "    if configurations:\n",
        "        payload[\"configurations\"] = configurations\n",
        "    \n",
        "    print(\"Creating evaluator...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Slug: {evaluator_slug}\")\n",
        "    print(f\"  Type: {evaluator_type}\")\n",
        "    print(f\"  Score Type: {score_value_type}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Evaluator created successfully\")\n",
        "    if 'id' in data:\n",
        "        print(f\"  Evaluator ID: {data.get('id')}\")\n",
        "    if 'evaluator_slug' in data:\n",
        "        print(f\"  Evaluator Slug: {data.get('evaluator_slug')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_experiment(name: str, description: str, dataset_id: str, \n",
        "                     workflows: List[Dict], evaluator_slugs: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"Create a new custom workflow experiment.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"dataset_id\": dataset_id,\n",
        "        \"workflows\": workflows,\n",
        "        \"evaluator_slugs\": evaluator_slugs\n",
        "    }\n",
        "    \n",
        "    print(\"Creating custom workflow experiment...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Dataset: {dataset_id}\")\n",
        "    print(f\"  Evaluators: {', '.join(evaluator_slugs)}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Experiment created with ID: {data.get('id')}\")\n",
        "    print(f\"  Status: {data.get('status')}\")\n",
        "    print(\"  Placeholder traces are being created asynchronously...\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def list_experiment_logs(exp_id: str, filters: Optional[Dict[str, Any]] = None, \n",
        "                        page: int = 1, page_size: int = 100) -> Dict[str, Any]:\n",
        "    \"\"\"List traces for an experiment with optional filtering.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/list/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    params = {\n",
        "        \"page\": page,\n",
        "        \"page_size\": page_size\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nListing experiment logs for {exp_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Params: {params}\")\n",
        "    if filters:\n",
        "        print(f\"  Filters: {json.dumps(filters, indent=2)}\")\n",
        "    \n",
        "    try:\n",
        "        if filters:\n",
        "            request_body = {\"filters\": filters}\n",
        "            print(f\"  Method: POST\")\n",
        "            print(f\"  Request Body: {json.dumps(request_body, indent=2)}\")\n",
        "            response = requests.post(url, headers=headers, json=request_body, params=params)\n",
        "        else:\n",
        "            print(f\"  Method: GET\")\n",
        "            response = requests.get(url, headers=headers, params=params)\n",
        "        \n",
        "        response.raise_for_status()\n",
        "        \n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"‚ùå Error listing logs: {e}\")\n",
        "        print(f\"   Status code: {e.response.status_code}\")\n",
        "        \n",
        "        try:\n",
        "            error_json = e.response.json()\n",
        "            print(f\"   Response: {error_json}\")\n",
        "        except:\n",
        "            print(f\"   Response (text): {e.response.text[:500]}\")\n",
        "        \n",
        "        if filters and e.response.status_code == 500:\n",
        "            print(\"\\n‚ö† Retrying without filters...\")\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "                response.raise_for_status()\n",
        "                print(\"‚úì GET without filters succeeded\")\n",
        "            except Exception as retry_error:\n",
        "                print(f\"‚ùå Retry also failed: {retry_error}\")\n",
        "                raise e\n",
        "        else:\n",
        "            raise\n",
        "    \n",
        "    data = response.json()\n",
        "    results = data.get('results', [])\n",
        "    print(f\"‚úì Found {len(results)} logs (page {page})\")\n",
        "    print(f\"  Total count: {data.get('count', 0)}\")\n",
        "    \n",
        "    if results:\n",
        "        status_counts = {}\n",
        "        for log in results:\n",
        "            status = log.get('status', 'unknown')\n",
        "            status_counts[status] = status_counts.get(status, 0) + 1\n",
        "        print(f\"  Status breakdown: {status_counts}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def get_trace_details(exp_id: str, trace_id: str, include_full_span_tree: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"Get detailed information about a specific trace.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/{trace_id}/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    params = {}\n",
        "    if include_full_span_tree:\n",
        "        params[\"detail\"] = 1\n",
        "    \n",
        "    print(f\"  Getting trace details...\")\n",
        "    print(f\"    URL: {url}\")\n",
        "    print(f\"    Method: GET\")\n",
        "    if params:\n",
        "        print(f\"    Params: {params}\")\n",
        "    \n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    return response.json()\n",
        "\n",
        "def submit_workflow_results(exp_id: str, trace_id: str, \n",
        "                           input_data: Any, output_data: Any,\n",
        "                           name: Optional[str] = None, \n",
        "                           metadata: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Update a placeholder trace with your custom workflow results.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/{trace_id}/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data\n",
        "    }\n",
        "    \n",
        "    if name:\n",
        "        payload[\"name\"] = name\n",
        "    if metadata:\n",
        "        payload[\"metadata\"] = metadata\n",
        "    \n",
        "    print(f\"    Submitting results to: {url}\")\n",
        "    print(f\"    Method: PATCH\")\n",
        "    print(f\"    Payload keys: {list(payload.keys())}\")\n",
        "    print(f\"    Input type: {type(input_data).__name__}\")\n",
        "    print(f\"    Output type: {type(output_data).__name__}\")\n",
        "    \n",
        "    response = requests.patch(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    updated_trace = response.json()\n",
        "    \n",
        "    print(f\"    Response status: {response.status_code}\")\n",
        "    \n",
        "    response_status = updated_trace.get('status')\n",
        "    if response_status:\n",
        "        print(f\"    Trace status: {response_status}\")\n",
        "    \n",
        "    return updated_trace\n",
        "\n",
        "def get_experiment_summary(exp_id: str, filters: Optional[List[Dict]] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Get aggregated summary statistics for experiment traces.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/summary/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nGetting experiment summary for {exp_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    \n",
        "    if filters:\n",
        "        request_body = {\"filters\": filters}\n",
        "        print(f\"  Method: POST\")\n",
        "        print(f\"  Request Body: {json.dumps(request_body, indent=2)}\")\n",
        "        response = requests.post(url, headers=headers, json=request_body)\n",
        "    else:\n",
        "        print(f\"  Method: GET\")\n",
        "        response = requests.get(url, headers=headers)\n",
        "    \n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"‚úì Summary retrieved:\")\n",
        "    print(f\"  Total traces: {data.get('total_count', 0)}\")\n",
        "    print(f\"  Total cost: ${data.get('total_cost', 0):.4f}\")\n",
        "    print(f\"  Total tokens: {data.get('total_tokens', 0)}\")\n",
        "    print(f\"  Avg latency: {data.get('avg_latency', 0):.2f}s\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def process_with_custom_logic(input_data: Any) -> Dict[str, Any]:\n",
        "    \"\"\"Your custom workflow processing logic.\"\"\"\n",
        "    try:\n",
        "        if isinstance(input_data, str):\n",
        "            try:\n",
        "                parsed_input = json.loads(input_data)\n",
        "            except:\n",
        "                parsed_input = input_data\n",
        "        else:\n",
        "            parsed_input = input_data\n",
        "        \n",
        "        result = {\n",
        "            \"status\": \"processed\",\n",
        "            \"message\": f\"Successfully processed input with {len(str(parsed_input))} characters\",\n",
        "            \"input_preview\": str(parsed_input)[:100],\n",
        "            \"custom_field\": \"your_custom_value\"\n",
        "        }\n",
        "        \n",
        "        return {\n",
        "            \"output\": result,\n",
        "            \"metadata\": {\n",
        "                \"processing_timestamp\": time.time(),\n",
        "                \"processor\": \"custom_workflow_v1\"\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"output\": {\n",
        "                \"status\": \"error\",\n",
        "                \"error_message\": str(e)\n",
        "            },\n",
        "            \"metadata\": {\n",
        "                \"processing_timestamp\": time.time(),\n",
        "                \"processor\": \"custom_workflow_v1\",\n",
        "                \"error\": True\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Variables\n",
        "\n",
        "These variables will track resources created throughout the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track resources created\n",
        "log_ids = []\n",
        "dataset_id = None\n",
        "evaluator_slug = None\n",
        "experiment_id = None\n",
        "trace_ids = []\n",
        "dataset_log_count = 0\n",
        "trace_count = 0\n",
        "processed_count = 0\n",
        "traces_with_evaluators = 0\n",
        "final_status_breakdown = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Sample Logs\n",
        "\n",
        "Create 3 sample logs that will be added to the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: Create Sample Logs\n",
            "======================================================================\n",
            "\n",
            "Creating log 1/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: completion_workflow_test_log_1\n",
            "  Span name: completion_workflow_test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"What is machine learning?\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"completion_workflow_test_log_1\",\n",
            "  \"span_name\": \"completion_workflow_test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): bf1e4c9890e649189a85bd2f539168ee\n",
            "‚úÖ Log created with ID: bf1e4c9890e64918...\n",
            "\n",
            "Creating log 2/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: completion_workflow_test_log_2\n",
            "  Span name: completion_workflow_test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Explain neural networks briefly.\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Neural networks are computing systems inspired by biological neural networks in animal brains.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"completion_workflow_test_log_2\",\n",
            "  \"span_name\": \"completion_workflow_test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): 3c5674e68be14a099327d2f48c165161\n",
            "‚úÖ Log created with ID: 3c5674e68be14a09...\n",
            "\n",
            "Creating log 3/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: completion_workflow_test_log_3\n",
            "  Span name: completion_workflow_test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"What is deep learning?\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Deep learning is a type of machine learning based on artificial neural networks with multiple layers.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"completion_workflow_test_log_3\",\n",
            "  \"span_name\": \"completion_workflow_test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): a4c988b2570c4712b6bc3fbbe73fcd3e\n",
            "‚úÖ Log created with ID: a4c988b2570c4712...\n",
            "‚úÖ Created 3 logs total\n",
            "‚ÑπÔ∏è  Waiting for logs to persist in database...\n",
            "\n",
            "Waiting 15 seconds for processing...\n",
            "‚úì Wait complete\n"
          ]
        }
      ],
      "source": [
        "print_step(1, \"Create Sample Logs\")\n",
        "\n",
        "log_examples = [\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is machine learning?\"}\n",
        "        ],\n",
        "        \"response\": \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience.\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Explain neural networks briefly.\"}\n",
        "        ],\n",
        "        \"response\": \"Neural networks are computing systems inspired by biological neural networks in animal brains.\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is deep learning?\"}\n",
        "        ],\n",
        "        \"response\": \"Deep learning is a type of machine learning based on artificial neural networks with multiple layers.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, example in enumerate(log_examples, 1):\n",
        "    print(f\"\\nCreating log {i}/{len(log_examples)}...\")\n",
        "    log_result = create_log(\n",
        "        model=example[\"model\"],\n",
        "        input_messages=example[\"messages\"],\n",
        "        output_message={\"role\": \"assistant\", \"content\": example[\"response\"]},\n",
        "        custom_identifier=f\"completion_workflow_test_log_{i}\",\n",
        "        span_name=\"completion_workflow_test\"\n",
        "    )\n",
        "    log_id = log_result.get('unique_id') or log_result.get('id')\n",
        "    if log_id:\n",
        "        log_ids.append(log_id)\n",
        "        print_success(f\"Log created with ID: {log_id[:16]}...\")\n",
        "\n",
        "print_success(f\"Created {len(log_ids)} logs total\")\n",
        "print_info(\"Waiting for logs to persist in database...\")\n",
        "wait_for_processing(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Dataset from Logs\n",
        "\n",
        "Create a dataset using the logs we just created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: Create Dataset from Logs\n",
            "======================================================================\n",
            "Creating dataset...\n",
            "  URL: https://api.keywordsai.co/api/datasets\n",
            "  Name: Completion workflow test\n",
            "  Type: sampling\n",
            "  Request Body: {\n",
            "  \"name\": \"Completion workflow test\",\n",
            "  \"description\": \"Dataset created from complete self-contained notebook\",\n",
            "  \"type\": \"sampling\",\n",
            "  \"start_time\": \"2025-12-02T10:49:57.614309Z\",\n",
            "  \"end_time\": \"2025-12-04T10:49:57.614309Z\",\n",
            "  \"initial_log_filters\": {\n",
            "    \"id\": {\n",
            "      \"value\": [\n",
            "        \"bf1e4c9890e649189a85bd2f539168ee\",\n",
            "        \"3c5674e68be14a099327d2f48c165161\",\n",
            "        \"a4c988b2570c4712b6bc3fbbe73fcd3e\"\n",
            "      ],\n",
            "      \"operator\": \"in\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3h/z7vpqhz947d5ckx70zcxmh080000gn/T/ipykernel_4366/2807819317.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  end_time = datetime.utcnow()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì Dataset created successfully\n",
            "  Dataset ID: 004b07da-7c97-4499-9daa-c4371e204cbc\n",
            "  Name: Completion workflow test\n",
            "  Status: initializing\n",
            "‚úÖ Dataset created with ID: 004b07da-7c97-4499-9daa-c4371e204cbc\n",
            "‚ÑπÔ∏è  Waiting for dataset to populate...\n",
            "\n",
            "Waiting 15 seconds for processing...\n",
            "‚úì Wait complete\n"
          ]
        }
      ],
      "source": [
        "print_step(2, \"Create Dataset from Logs\")\n",
        "\n",
        "end_time = datetime.utcnow()\n",
        "start_time = end_time - timedelta(days=2)\n",
        "\n",
        "initial_filters = {\n",
        "    \"id\": {\n",
        "        \"value\": log_ids,\n",
        "        \"operator\": \"in\"\n",
        "    }\n",
        "}\n",
        "\n",
        "dataset_result = create_dataset(\n",
        "    name=\"Completion workflow test\",\n",
        "    description=\"Dataset created from complete self-contained notebook\",\n",
        "    dataset_type=\"sampling\",\n",
        "    start_time=start_time.isoformat() + \"Z\",\n",
        "    end_time=end_time.isoformat() + \"Z\",\n",
        "    initial_log_filters=initial_filters\n",
        ")\n",
        "\n",
        "dataset_id = dataset_result.get('id')\n",
        "print_success(f\"Dataset created with ID: {dataset_id}\")\n",
        "print_info(\"Waiting for dataset to populate...\")\n",
        "wait_for_processing(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify Dataset Contains the Logs \n",
        "\n",
        "This is a critical verification step to ensure the dataset actually contains the logs we created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: Verify Dataset Contains the Logs\n",
            "======================================================================\n",
            "\n",
            "Listing logs for dataset 004b07da-7c97-4499-9daa-c4371e204cbc...\n",
            "  URL: https://api.keywordsai.co/api/datasets/004b07da-7c97-4499-9daa-c4371e204cbc/logs/list\n",
            "  Method: GET\n",
            "  Params: {'page': 1, 'page_size': 100}\n",
            "‚úì Retrieved 3 logs (page 1)\n",
            "  Total logs in dataset: 3\n",
            "\n",
            "  üìã First log structure:\n",
            "    Keys: ['id', 'organization_id', 'organization_key_id', 'environment', 'timestamp', 'start_time', 'prompt_id', 'prompt_name', 'trace_unique_id', 'customer_identifier', 'thread_identifier', 'custom_identifier', 'unique_organization_id', 'log_type', 'prompt_tokens', 'completion_tokens', 'total_request_tokens', 'cost', 'model', 'latency', 'tokens_per_second', 'time_to_first_token', 'routing_time', 'status_code', 'status', 'blurred', 'metadata', 'storage_object_key', 'updated_storage_object_key', 'system', 'prompt', 'completion', 'unique_id', 'dataset_id', 'updated_at', 'updated_by_email', 'input', 'output', 'annotation_status', 'annotation_completed_by', 'scores']\n",
            "    Log ID: 3c5674e68be14a099327d2f48c165161\n",
            "    Input preview: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"Explain neural networks...\n",
            "    Output preview: {\"content\": \"Neural networks are computing systems inspired by biological neural networks in animal ...\n",
            "Expected logs: 3\n",
            "Dataset contains: 3 logs\n",
            "Retrieved for verification: 3 logs\n",
            "‚úÖ Dataset successfully populated with all 3 logs!\n",
            "\n",
            "üìã Sample log from dataset:\n",
            "  ID: 3c5674e68be14a099327d2f4...\n",
            "  Has input: Yes (128 chars)\n",
            "  Has output: Yes (130 chars)\n"
          ]
        }
      ],
      "source": [
        "print_step(3, \"Verify Dataset Contains the Logs\")\n",
        "\n",
        "dataset_logs = list_dataset_logs(dataset_id, page=1, page_size=100)\n",
        "dataset_log_count = len(dataset_logs.get('results', []))\n",
        "total_dataset_logs = dataset_logs.get('count', 0)\n",
        "\n",
        "print(f\"Expected logs: {len(log_ids)}\")\n",
        "print(f\"Dataset contains: {total_dataset_logs} logs\")\n",
        "print(f\"Retrieved for verification: {dataset_log_count} logs\")\n",
        "\n",
        "if dataset_log_count == 0:\n",
        "    print_error(\"Dataset is empty! Workflow cannot proceed.\")\n",
        "    raise Exception(\"Dataset is empty\")\n",
        "elif dataset_log_count < len(log_ids):\n",
        "    print_warning(f\"Expected {len(log_ids)} but found {dataset_log_count}\")\n",
        "    print_info(\"Some logs may not have been added yet, but proceeding...\")\n",
        "else:\n",
        "    print_success(f\"Dataset successfully populated with all {dataset_log_count} logs!\")\n",
        "\n",
        "if dataset_log_count > 0:\n",
        "    first_log = dataset_logs['results'][0]\n",
        "    print(f\"\\nüìã Sample log from dataset:\")\n",
        "    print(f\"  ID: {first_log.get('id', 'N/A')[:24]}...\")\n",
        "    if 'input' in first_log:\n",
        "        print(f\"  Has input: Yes ({len(str(first_log['input']))} chars)\")\n",
        "    if 'output' in first_log:\n",
        "        print(f\"  Has output: Yes ({len(str(first_log['output']))} chars)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Custom Evaluator\n",
        "\n",
        "Create an LLM-based evaluator that rates response quality on a 1-5 scale based on accuracy, relevance, and completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: Create Custom Evaluator\n",
            "======================================================================\n",
            "Creating evaluator...\n",
            "  URL: https://api.keywordsai.co/api/evaluators\n",
            "  Name: Completion workflow test\n",
            "  Slug: completion_workflow_test_eval_1764845414\n",
            "  Type: llm\n",
            "  Score Type: numerical\n",
            "  Request Body: {\n",
            "  \"name\": \"Completion workflow test\",\n",
            "  \"evaluator_slug\": \"completion_workflow_test_eval_1764845414\",\n",
            "  \"type\": \"llm\",\n",
            "  \"score_value_type\": \"numerical\",\n",
            "  \"description\": \"Evaluates response quality on a 1-5 scale\",\n",
            "  \"configurations\": {\n",
            "    \"evaluator_definition\": \"Rate the response quality based on accuracy, relevance, and completeness.\\n<llm_input>{{llm_input}}</llm_input>\\n<llm_output>{{llm_output}}</llm_output>\",\n",
            "    \"scoring_rubric\": \"1=Poor, 2=Fair, 3=Good, 4=Very Good, 5=Excellent\",\n",
            "    \"llm_engine\": \"gpt-4o-mini\",\n",
            "    \"model_options\": {\n",
            "      \"temperature\": 0.1,\n",
            "      \"max_tokens\": 200\n",
            "    },\n",
            "    \"min_score\": 1.0,\n",
            "    \"max_score\": 5.0,\n",
            "    \"passing_score\": 3.0\n",
            "  }\n",
            "}\n",
            "\n",
            "‚úì Evaluator created successfully\n",
            "  Evaluator ID: a8d14670-0bd9-4510-a68f-266a68e28e21\n",
            "  Evaluator Slug: completion_workflow_test_eval_1764845414\n",
            "‚úÖ Evaluator created with slug: completion_workflow_test_eval_1764845414\n"
          ]
        }
      ],
      "source": [
        "print_step(4, \"Create Custom Evaluator\")\n",
        "\n",
        "\n",
        "evaluator_slug = f\"completion_workflow_test_eval_{int(time.time())}\"\n",
        "\n",
        "evaluator_result = create_evaluator(\n",
        "    name=\"Completion workflow test\",\n",
        "    evaluator_slug=evaluator_slug,\n",
        "    evaluator_type=\"llm\",\n",
        "    score_value_type=\"numerical\",\n",
        "    description=\"Evaluates response quality on a 1-5 scale\",\n",
        "    configurations={\n",
        "        \"evaluator_definition\": \"Rate the response quality based on accuracy, relevance, and completeness.\\n<llm_input>{{llm_input}}</llm_input>\\n<llm_output>{{llm_output}}</llm_output>\",\n",
        "        \"scoring_rubric\": \"1=Poor, 2=Fair, 3=Good, 4=Very Good, 5=Excellent\",\n",
        "        \"llm_engine\": \"gpt-4o-mini\",\n",
        "        \"model_options\": {\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_tokens\": 200\n",
        "        },\n",
        "        \"min_score\": 1.0,\n",
        "        \"max_score\": 5.0,\n",
        "        \"passing_score\": 3.0\n",
        "    }\n",
        ")\n",
        "\n",
        "print_success(f\"Evaluator created with slug: {evaluator_slug}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Experiment with 2 Completion Workflows\n",
        "\n",
        "Create an experiment with 2 consecutive completion workflows that chain head-to-tail.\n",
        "- Workflow 1: Lower temperature (0.3) for more focused/deterministic output\n",
        "- Workflow 2: Higher temperature (0.7) for more creative/expansive output\n",
        "\n",
        "The output of Workflow 1 becomes the input of Workflow 2 (head-to-tail chaining).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: Create Experiment with 2 Completion Workflows\n",
            "======================================================================\n",
            "Creating custom workflow experiment...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/\n",
            "  Name: Completion workflow test\n",
            "  Dataset: 004b07da-7c97-4499-9daa-c4371e204cbc\n",
            "  Evaluators: completion_workflow_test_eval_1764845414\n",
            "  Request Body: {\n",
            "  \"name\": \"Completion workflow test\",\n",
            "  \"description\": \"Testing 2 consecutive completion workflows with chaining\",\n",
            "  \"dataset_id\": \"004b07da-7c97-4499-9daa-c4371e204cbc\",\n",
            "  \"workflows\": [\n",
            "    {\n",
            "      \"type\": \"completion\",\n",
            "      \"config\": {\n",
            "        \"model\": \"gpt-4o-mini\",\n",
            "        \"temperature\": 0.3,\n",
            "        \"max_tokens\": 100\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"completion\",\n",
            "      \"config\": {\n",
            "        \"model\": \"gpt-4o-mini\",\n",
            "        \"temperature\": 0.7,\n",
            "        \"max_tokens\": 200\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"evaluator_slugs\": [\n",
            "    \"completion_workflow_test_eval_1764845414\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "‚úì Experiment created with ID: ccbd6c0305dd40bfb603bfa74c6b7cca\n",
            "  Status: pending\n",
            "  Placeholder traces are being created asynchronously...\n",
            "‚úÖ Experiment created with ID: ccbd6c0305dd40bfb603bfa74c6b7cca\n",
            "‚ÑπÔ∏è  Workflows executing asynchronously via Celery...\n",
            "‚ÑπÔ∏è  Workflow 1: Lower temperature (0.3) for focused answers\n",
            "‚ÑπÔ∏è  Workflow 2: Higher temperature (0.7) for creative expansion\n"
          ]
        }
      ],
      "source": [
        "print_step(5, \"Create Experiment with 2 Completion Workflows\")\n",
        "\n",
        "experiment_data = create_experiment(\n",
        "    name=\"Completion workflow test\",\n",
        "    description=\"Testing 2 consecutive completion workflows with chaining\",\n",
        "    dataset_id=dataset_id,\n",
        "    workflows=[\n",
        "        {\n",
        "            \"type\": \"completion\",\n",
        "            \"config\": {\n",
        "                \"model\": \"gpt-4o-mini\",\n",
        "                \"temperature\": 0.3,\n",
        "                \"max_tokens\": 100\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"completion\",\n",
        "            \"config\": {\n",
        "                \"model\": \"gpt-4o-mini\",\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_tokens\": 200\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    evaluator_slugs=[evaluator_slug]\n",
        ")\n",
        "\n",
        "experiment_id = experiment_data.get('id')\n",
        "print_success(f\"Experiment created with ID: {experiment_id}\")\n",
        "print_info(\"Workflows executing asynchronously via Celery...\")\n",
        "print_info(\"Workflow 1: Lower temperature (0.3) for focused answers\")\n",
        "print_info(\"Workflow 2: Higher temperature (0.7) for creative expansion\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Wait for Workflows to Complete\n",
        "\n",
        "Wait for async workflow execution (both workflows) and retrieve the completed traces with retry logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 6: Wait for Workflows to Complete\n",
            "======================================================================\n",
            "‚ÑπÔ∏è  Waiting for 2 completion workflows to execute (with retry)...\n",
            "‚ÑπÔ∏è  This may take longer due to 2 consecutive LLM calls per trace...\n",
            "  Attempt 1/10...\n",
            "\n",
            "Waiting 10 seconds for processing...\n",
            "‚úì Wait complete\n",
            "\n",
            "Listing experiment logs for ccbd6c0305dd40bfb603bfa74c6b7cca...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 10}\n",
            "  Method: GET\n",
            "‚úì Found 2 logs (page 1)\n",
            "  Total count: 2\n",
            "  Status breakdown: {'success': 2}\n",
            "  Found 2 traces (2 completed)\n",
            "‚úÖ Found 2 completed traces on attempt 1\n",
            "\n",
            "Listing experiment logs for ccbd6c0305dd40bfb603bfa74c6b7cca...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 10}\n",
            "  Method: GET\n",
            "‚úì Found 2 logs (page 1)\n",
            "  Total count: 2\n",
            "  Status breakdown: {'success': 2}\n",
            "\n",
            "Found 2 traces\n",
            "‚úÖ Successfully retrieved 2 traces\n",
            "\n",
            "Status breakdown:\n",
            "  success: 2\n"
          ]
        }
      ],
      "source": [
        "print_step(6, \"Wait for Workflows to Complete\")\n",
        "\n",
        "print_info(\"Waiting for 2 completion workflows to execute (with retry)...\")\n",
        "print_info(\"This may take longer due to 2 consecutive LLM calls per trace...\")\n",
        "\n",
        "trace_count = 0\n",
        "max_retries = 10\n",
        "retry_wait = 10\n",
        "\n",
        "for attempt in range(1, max_retries + 1):\n",
        "    print(f\"  Attempt {attempt}/{max_retries}...\")\n",
        "    wait_for_processing(retry_wait)\n",
        "    \n",
        "    traces_response = list_experiment_logs(experiment_id, filters=None, page_size=10)\n",
        "    trace_count = len(traces_response.get('results', []))\n",
        "    \n",
        "    if trace_count > 0:\n",
        "        # Check if traces are completed (not just created)\n",
        "        completed_count = sum(1 for t in traces_response.get('results', []) \n",
        "                             if t.get('status') not in ['pending', 'processing'])\n",
        "        print(f\"  Found {trace_count} traces ({completed_count} completed)\")\n",
        "        \n",
        "        if completed_count > 0:\n",
        "            print_success(f\"Found {completed_count} completed traces on attempt {attempt}\")\n",
        "            break\n",
        "        elif attempt < max_retries:\n",
        "            print_info(f\"Traces still processing, waiting {retry_wait} more seconds...\")\n",
        "    else:\n",
        "        if attempt < max_retries:\n",
        "            print_info(f\"No traces yet, waiting {retry_wait} more seconds...\")\n",
        "\n",
        "traces = list_experiment_logs(experiment_id, filters=None, page_size=10)\n",
        "trace_count = len(traces.get('results', []))\n",
        "\n",
        "print(f\"\\nFound {trace_count} traces\")\n",
        "\n",
        "if trace_count == 0:\n",
        "    print_error(\"No traces found after multiple retries!\")\n",
        "    raise Exception(\"No traces found\")\n",
        "\n",
        "print_success(f\"Successfully retrieved {trace_count} traces\")\n",
        "\n",
        "status_breakdown = {}\n",
        "for trace in traces.get('results', []):\n",
        "    status = trace.get('status', 'unknown')\n",
        "    status_breakdown[status] = status_breakdown.get(status, 0) + 1\n",
        "\n",
        "print(f\"\\nStatus breakdown:\")\n",
        "for status, count in status_breakdown.items():\n",
        "    print(f\"  {status}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Verify Workflow Chaining\n",
        "\n",
        "Verify that the output of Workflow 1 became the input of Workflow 2.\n",
        "This demonstrates the head-to-tail chaining behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 7: Verify Workflow Chaining\n",
            "======================================================================\n",
            "\n",
            "üîç Inspecting trace 1/2 (f25a9f223763e670...)...\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/f25a9f223763e670c9aab83612634748/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  Found 4 workflow span(s)\n",
            "\n",
            "  Workflow 1:\n",
            "    Name: workflow_execution\n",
            "    Output: {\"content\": \"and can learn to represent data at multiple levels of abstraction.\\n\\n2. **Layer Structure**: Deep learning models are characterized by t...\n",
            "\n",
            "  Workflow 2:\n",
            "    Name: Experiment Workflow.completion\n",
            "    Input: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"What is deep learning?\", \"role\": \"user\"}]...\n",
            "‚úÖ ‚úÖ Chaining detected: Workflow 1 output ‚Üí Workflow 2 input\n",
            "\n",
            "üîç Inspecting trace 2/2 (799824356cbc4d77...)...\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/799824356cbc4d77a359b385d53922b2/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  Found 4 workflow span(s)\n",
            "\n",
            "  Workflow 1:\n",
            "    Name: workflow_execution\n",
            "    Output: {\"content\": \"unstructured (like images, text, or audio).\\n\\n2. **Algorithms**: These are the mathematical formulas and rules that machine learning mod...\n",
            "\n",
            "  Workflow 2:\n",
            "    Name: Experiment Workflow.completion\n",
            "    Input: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"What is machine learning?\", \"role\": \"user\"}]...\n",
            "‚úÖ ‚úÖ Chaining detected: Workflow 1 output ‚Üí Workflow 2 input\n",
            "\n",
            "üìä Chaining Summary:\n",
            "  Traces inspected: 2\n",
            "  Chaining verified: 2/2\n",
            "‚úÖ Workflow chaining is working correctly!\n"
          ]
        }
      ],
      "source": [
        "print_step(7, \"Verify Workflow Chaining\")\n",
        "\n",
        "max_to_inspect = min(trace_count, 3)\n",
        "chaining_verified_count = 0\n",
        "\n",
        "for i, trace in enumerate(traces['results'][:max_to_inspect], 1):\n",
        "    trace_id = trace.get('id')\n",
        "    trace_ids.append(trace_id)\n",
        "    \n",
        "    print(f\"\\nüîç Inspecting trace {i}/{max_to_inspect} ({trace_id[:16]}...)...\")\n",
        "    \n",
        "    trace_details = get_trace_details(experiment_id, trace_id, include_full_span_tree=True)\n",
        "    span_tree = trace_details.get('span_tree', [])\n",
        "    \n",
        "    # Find workflow spans (should be children of root)\n",
        "    workflow_spans = []\n",
        "    \n",
        "    def collect_workflow_spans(spans):\n",
        "        for span in spans:\n",
        "            if 'workflow' in span.get('span_name', '').lower() or 'completion' in span.get('span_name', '').lower():\n",
        "                workflow_spans.append(span)\n",
        "            if 'children' in span and span['children']:\n",
        "                collect_workflow_spans(span['children'])\n",
        "    \n",
        "    collect_workflow_spans(span_tree)\n",
        "    \n",
        "    print(f\"  Found {len(workflow_spans)} workflow span(s)\")\n",
        "    \n",
        "    if len(workflow_spans) >= 2:\n",
        "        wf1 = workflow_spans[0]\n",
        "        wf2 = workflow_spans[1]\n",
        "        \n",
        "        wf1_output = str(wf1.get('output', ''))\n",
        "        wf2_input = str(wf2.get('input', ''))\n",
        "        \n",
        "        print(f\"\\n  Workflow 1:\")\n",
        "        print(f\"    Name: {wf1.get('span_name')}\")\n",
        "        print(f\"    Output: {wf1_output[:150]}...\")\n",
        "        \n",
        "        print(f\"\\n  Workflow 2:\")\n",
        "        print(f\"    Name: {wf2.get('span_name')}\")\n",
        "        print(f\"    Input: {wf2_input[:150]}...\")\n",
        "        \n",
        "        # Check if chaining occurred (output has content, input has content)\n",
        "        has_chaining = len(wf1_output) > 10 and len(wf2_input) > 10\n",
        "        \n",
        "        if has_chaining:\n",
        "            print_success(\"‚úÖ Chaining detected: Workflow 1 output ‚Üí Workflow 2 input\")\n",
        "            chaining_verified_count += 1\n",
        "        else:\n",
        "            print_warning(\"‚ö†Ô∏è Chaining unclear: outputs/inputs may be empty\")\n",
        "    else:\n",
        "        print_warning(f\"  Expected 2 workflow spans, found {len(workflow_spans)}\")\n",
        "\n",
        "print(f\"\\nüìä Chaining Summary:\")\n",
        "print(f\"  Traces inspected: {max_to_inspect}\")\n",
        "print(f\"  Chaining verified: {chaining_verified_count}/{max_to_inspect}\")\n",
        "\n",
        "if chaining_verified_count > 0:\n",
        "    print_success(\"Workflow chaining is working correctly!\")\n",
        "else:\n",
        "    print_warning(\"Chaining could not be verified\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Verify Evaluators and Final Results \n",
        "\n",
        "Check that evaluators ran on the final output from Workflow 2.\n",
        "Get comprehensive results including status breakdown.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 8: Verify Experiment Results\n",
            "======================================================================\n",
            "\n",
            "Getting experiment summary for ccbd6c0305dd40bfb603bfa74c6b7cca...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/summary/\n",
            "  Method: GET\n",
            "‚úì Summary retrieved:\n",
            "  Total traces: 3\n",
            "  Total cost: $0.0012\n",
            "  Total tokens: 2574\n",
            "  Avg latency: 9.13s\n",
            "\n",
            "üìä Experiment Summary:\n",
            "  Total traces: 3\n",
            "  Total cost: $0.0012\n",
            "  Total tokens: 2574\n",
            "  Avg latency: 9.13s\n",
            "\n",
            "Listing experiment logs for ccbd6c0305dd40bfb603bfa74c6b7cca...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 100}\n",
            "  Method: GET\n",
            "‚úì Found 3 logs (page 1)\n",
            "  Total count: 3\n",
            "  Status breakdown: {'success': 3}\n",
            "\n",
            "üìà Final Status Breakdown:\n",
            "  success: 3 (100.0%)\n",
            "\n",
            "üîç Checking Evaluator Execution:\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/f25a9f223763e670c9aab83612634748/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  ‚ö†Ô∏è  Trace f25a9f223763e670... has no evaluator results yet\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/799824356cbc4d77a359b385d53922b2/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  ‚ö†Ô∏è  Trace 799824356cbc4d77... has no evaluator results yet\n",
            "‚ö†Ô∏è  No evaluator results found (may still be processing)\n"
          ]
        }
      ],
      "source": [
        "print_step(8, \"Verify Experiment Results\")\n",
        "\n",
        "try:\n",
        "    final_summary = get_experiment_summary(experiment_id)\n",
        "    print(f\"\\nüìä Experiment Summary:\")\n",
        "    print(f\"  Total traces: {final_summary.get('total_count', 0)}\")\n",
        "    print(f\"  Total cost: ${final_summary.get('total_cost', 0):.4f}\")\n",
        "    print(f\"  Total tokens: {final_summary.get('total_tokens', 0)}\")\n",
        "    print(f\"  Avg latency: {final_summary.get('avg_latency', 0):.2f}s\")\n",
        "except Exception as e:\n",
        "    print_warning(f\"Could not get summary: {e}\")\n",
        "    final_summary = {}\n",
        "\n",
        "all_traces = list_experiment_logs(experiment_id, filters=None)\n",
        "final_status_breakdown = {}\n",
        "for trace in all_traces.get('results', []):\n",
        "    status = trace.get('status', 'unknown')\n",
        "    final_status_breakdown[status] = final_status_breakdown.get(status, 0) + 1\n",
        "\n",
        "print(f\"\\nüìà Final Status Breakdown:\")\n",
        "for status, count in final_status_breakdown.items():\n",
        "    total = all_traces.get('count', 1)\n",
        "    percentage = (count / total * 100) if total > 0 else 0\n",
        "    print(f\"  {status}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüîç Checking Evaluator Execution:\")\n",
        "traces_with_evaluators = 0\n",
        "\n",
        "for trace_id in trace_ids[:3]:\n",
        "    trace_detail = get_trace_details(experiment_id, trace_id, include_full_span_tree=True)\n",
        "    span_tree = trace_detail.get('span_tree', [])\n",
        "    \n",
        "    evaluator_spans = [\n",
        "        span for span in span_tree\n",
        "        if span.get('span_type') == 'SCORE' or 'evaluator' in span.get('span_name', '').lower()\n",
        "    ]\n",
        "    \n",
        "    if evaluator_spans:\n",
        "        traces_with_evaluators += 1\n",
        "        print(f\"  ‚úì Trace {trace_id[:16]}... has {len(evaluator_spans)} evaluator span(s)\")\n",
        "        for eval_span in evaluator_spans:\n",
        "            span_name = eval_span.get('span_name', 'unknown')\n",
        "            score = eval_span.get('score', 'N/A')\n",
        "            print(f\"    - {span_name}: score = {score}\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  Trace {trace_id[:16]}... has no evaluator results yet\")\n",
        "\n",
        "if traces_with_evaluators > 0:\n",
        "    print_success(f\"Evaluators executed on {traces_with_evaluators}/{len(trace_ids[:3])} sampled traces\")\n",
        "else:\n",
        "    print_warning(\"No evaluator results found (may still be processing)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: View Full Span Tree Structure\n",
        "\n",
        "Inspect the complete span tree to understand the hierarchy:\n",
        "- ROOT span (experiment_trace)\n",
        "- Workflow 1 span (completion - summarization)\n",
        "- Workflow 2 span (completion - expansion)  \n",
        "- Evaluator span(s) (scoring final output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 9: View Full Span Tree Structure\n",
            "======================================================================\n",
            "\n",
            "üîç Detailed inspection of trace: f25a9f223763e670c9aab83612634748\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/ccbd6c0305dd40bfb603bfa74c6b7cca/logs/f25a9f223763e670c9aab83612634748/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "\n",
            "üìã Trace-level summary:\n",
            "  Total spans: 5\n",
            "  LLM calls: 0\n",
            "  Total cost: $0.000399\n",
            "  Duration: 9.13s\n",
            "  Status: success\n",
            "\n",
            "üå≤ Span Tree Structure (hierarchical):\n",
            "\n",
            "[1] üéØ ROOT - experiment_trace\n",
            "    Status: success\n",
            "    Type: workflow\n",
            "    Children: 2 span(s)\n",
            "\n",
            "  [1] ‚öôÔ∏è WORKFLOW - workflow_execution\n",
            "      Status: success\n",
            "      Type: chat\n",
            "      Input: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"What is deep learning?\"...\n",
            "      Output: {\"content\": \"and can learn to represent data at multiple levels of abstraction.\\n\\n2. **Layer Struct...\n",
            "      Children: 2 span(s)\n",
            "\n",
            "    [1] ‚öôÔ∏è WORKFLOW - Experiment Workflow.completion\n",
            "        Status: completed\n",
            "        Type: workflow\n",
            "        Input: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"What is deep learning?\"...\n",
            "        Output: {\"annotations\": [], \"content\": \"Deep learning is a subset of machine learning, which itself is a bra...\n",
            "\n",
            "    [2] ‚öôÔ∏è WORKFLOW - Experiment Workflow.completion\n",
            "        Status: completed\n",
            "        Type: workflow\n",
            "        Input: {\"annotations\": [], \"content\": \"Deep learning is a subset of machine learning, which itself is a bra...\n",
            "        Output: {\"annotations\": [], \"content\": \"and can learn to represent data at multiple levels of abstraction.\\n...\n",
            "\n",
            "  [2] ‚öôÔ∏è WORKFLOW - evaluator.completion_workflow_test_eval_1764845414\n",
            "      Status: completed\n",
            "      Type: score\n",
            "      Input: {\"dataset_id\": \"004b07da-7c97-4499-9daa-c4371e204cbc\", \"experiment_id\": \"ccbd6c0305dd40bfb603bfa74c6...\n",
            "      Output: {\"completion_workflow_test_eval_1764845414\": {\"categorical_value\": [], \"evaluator_id\": \"completion_w...\n",
            "      Evaluation: {\"completion_workflow_test_eval_1764845414\": {\"categorical_value\": [], \"evaluator_id\": \"completion_workflow_test_eval_1764845414\", \"primary_score\": 3....\n",
            "\n",
            "üìà Span Summary:\n",
            "  Total spans (including root): 5\n",
            "  Workflow spans: 4\n",
            "  Evaluator spans: 1\n",
            "‚úÖ ‚úÖ Found 2+ workflow spans (chaining confirmed)\n",
            "‚úÖ ‚úÖ Found 1 evaluator span(s)\n"
          ]
        }
      ],
      "source": [
        "print_step(9, \"View Full Span Tree Structure\")\n",
        "\n",
        "# Get first trace with full details\n",
        "if trace_ids:\n",
        "    first_trace_id = trace_ids[0]\n",
        "    print(f\"\\nüîç Detailed inspection of trace: {first_trace_id}\")\n",
        "    \n",
        "    trace_detail = get_trace_details(experiment_id, first_trace_id, include_full_span_tree=True)\n",
        "    \n",
        "    print(f\"\\nüìã Trace-level summary:\")\n",
        "    print(f\"  Total spans: {trace_detail.get('span_count', 0)}\")\n",
        "    print(f\"  LLM calls: {trace_detail.get('llm_call_count', 0)}\")\n",
        "    print(f\"  Total cost: ${trace_detail.get('total_cost', 0):.6f}\")\n",
        "    print(f\"  Duration: {trace_detail.get('duration', 0):.2f}s\")\n",
        "    print(f\"  Status: {trace_detail.get('status')}\")\n",
        "    \n",
        "    span_tree = trace_detail.get('span_tree', [])\n",
        "    print(f\"\\nüå≤ Span Tree Structure (hierarchical):\")\n",
        "    \n",
        "    if not span_tree:\n",
        "        print_error(\"Span tree is empty!\")\n",
        "    else:\n",
        "        def print_span_tree(spans, indent=0):\n",
        "            for i, span in enumerate(spans, 1):\n",
        "                prefix = \"  \" * indent\n",
        "                span_name = span.get('span_name', 'N/A')\n",
        "                span_type = span.get('log_type', span.get('span_type', 'N/A'))\n",
        "                status = span.get('status', 'N/A')\n",
        "                \n",
        "                # Determine span category\n",
        "                if span_name == 'experiment_trace':\n",
        "                    category = \"üéØ ROOT\"\n",
        "                elif 'workflow' in span_name.lower() or 'completion' in span_name.lower():\n",
        "                    category = \"‚öôÔ∏è WORKFLOW\"\n",
        "                elif 'evaluator' in span_name.lower():\n",
        "                    category = \"üìä EVALUATOR\"\n",
        "                else:\n",
        "                    category = \"üì¶ OTHER\"\n",
        "                \n",
        "                print(f\"\\n{prefix}[{i}] {category} - {span_name}\")\n",
        "                print(f\"{prefix}    Status: {status}\")\n",
        "                print(f\"{prefix}    Type: {span_type}\")\n",
        "                \n",
        "                # Show input/output for workflow spans\n",
        "                if 'workflow' in span_name.lower() or 'completion' in span_name.lower():\n",
        "                    input_str = str(span.get('input', ''))\n",
        "                    output_str = str(span.get('output', ''))\n",
        "                    if input_str:\n",
        "                        print(f\"{prefix}    Input: {input_str[:100]}...\")\n",
        "                    if output_str:\n",
        "                        print(f\"{prefix}    Output: {output_str[:100]}...\")\n",
        "                \n",
        "                # Show score for evaluator spans\n",
        "                if 'evaluator' in span_name.lower():\n",
        "                    output = span.get('output', '')\n",
        "                    print(f\"{prefix}    Evaluation: {str(output)[:150]}...\")\n",
        "                \n",
        "                # Recurse into children\n",
        "                children = span.get('children', [])\n",
        "                if children:\n",
        "                    print(f\"{prefix}    Children: {len(children)} span(s)\")\n",
        "                    print_span_tree(children, indent + 1)\n",
        "        \n",
        "        print_span_tree(span_tree)\n",
        "        \n",
        "        # Summary counts\n",
        "        all_spans = []\n",
        "        def collect_all_spans(spans):\n",
        "            for span in spans:\n",
        "                all_spans.append(span)\n",
        "                if 'children' in span and span['children']:\n",
        "                    collect_all_spans(span['children'])\n",
        "        \n",
        "        collect_all_spans(span_tree)\n",
        "        \n",
        "        workflow_count = sum(1 for s in all_spans if 'workflow' in s.get('span_name', '').lower() or 'completion' in s.get('span_name', '').lower())\n",
        "        evaluator_count = sum(1 for s in all_spans if 'evaluator' in s.get('span_name', '').lower())\n",
        "        \n",
        "        print(f\"\\nüìà Span Summary:\")\n",
        "        print(f\"  Total spans (including root): {len(all_spans)}\")\n",
        "        print(f\"  Workflow spans: {workflow_count}\")\n",
        "        print(f\"  Evaluator spans: {evaluator_count}\")\n",
        "        \n",
        "        if workflow_count >= 2:\n",
        "            print_success(\"‚úÖ Found 2+ workflow spans (chaining confirmed)\")\n",
        "        else:\n",
        "            print_warning(f\"‚ö†Ô∏è Expected 2 workflow spans, found {workflow_count}\")\n",
        "        \n",
        "        if evaluator_count > 0:\n",
        "            print_success(f\"‚úÖ Found {evaluator_count} evaluator span(s)\")\n",
        "        else:\n",
        "            print_warning(\"‚ö†Ô∏è No evaluator spans found\")\n",
        "else:\n",
        "    print_warning(\"No trace IDs available to inspect\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
